{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(price):  # e.g. 'HK$1,234.00'\n",
    "    currency = price.split('HK$')[1]\n",
    "    currency = currency.split('.')[0]\n",
    "    if ',' in currency:\n",
    "        currency = currency.split(',')\n",
    "        currency = ''.join(currency)\n",
    "    currency = float(currency)\n",
    "    return currency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function for interrupted run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Main: Start')\n",
    "start_time = time.time()\n",
    "\n",
    "max_workers = os.cpu_count()\n",
    "print(\"CPU count:\", max_workers)\n",
    "\n",
    "# define the directory name\n",
    "dir_name = 'sasa'\n",
    "\n",
    "# check if the directory exists\n",
    "if not os.path.exists(dir_name):\n",
    "    # if not, create it\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "# read csv files from the directory\n",
    "ls = os.listdir(dir_name)\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "count_of_files = 0\n",
    "for file in ls:\n",
    "    if file.startswith('sasa_') and file.endswith(datetime.now().strftime('%Y%m%d')+'.csv'):  # '20240227.csv'):\n",
    "        print(file)\n",
    "        df = pd.read_csv('sasa/'+file)\n",
    "\n",
    "        master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "        count_of_files += 1\n",
    "\n",
    "# promo_filename = \"sasa/tmp_promotion_items_\" + datetime.now().strftime('%Y%m%d') + \".csv\"\n",
    "# index_filename = \"sasa/tmp_index_items_\" + datetime.now().strftime('%Y%m%d') + \".csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(master_df)\n",
    "print('Before:', master_df.shape)\n",
    "\n",
    "# Remove duplicates from the master_df DataFrame in Product ID\n",
    "master_df = master_df.drop_duplicates(subset='Product ID')\n",
    "\n",
    "print('After:', master_df.shape)\n",
    "\n",
    "promotion_df = pd.DataFrame()\n",
    "index_df = pd.DataFrame()\n",
    "\n",
    "# save master_df\n",
    "master_df.to_csv('sasa/tmp_master_df.csv', index=False)\n",
    "# display(master_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if count_of_files > 0:\n",
    "    categories = master_df['Category']\n",
    "    product_ids = master_df['Product ID']\n",
    "    sasa_urls = master_df['Link']\n",
    "    # print('Product IDs:', product_ids)\n",
    "\n",
    "    #list of tuples\n",
    "    product_info = list(zip(categories, product_ids, sasa_urls))\n",
    "\n",
    "    if os.path.exists(promo_filename) and os.path.exists(index_filename):\n",
    "        file1 = pd.read_csv(promo_filename)\n",
    "        file2 = pd.read_csv(index_filename)\n",
    "\n",
    "        if file1.empty or file2.empty:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            promo_items = list(set(file1['Product ID'].tolist()))\n",
    "            index_items = list(set(file2['Product ID'].tolist()))\n",
    "\n",
    "            # If product ID is in the promo_items list and index list, add it o id to remove\n",
    "            id_to_remove = []\n",
    "\n",
    "            for p in promo_items:\n",
    "                if p in index_items:\n",
    "                    id_to_remove.append(p)\n",
    "\n",
    "            print('Before:', len(product_info), '\\n')\n",
    "\n",
    "            new_product_info = []\n",
    "            for p in product_info:\n",
    "                if p[1] not in id_to_remove:\n",
    "                    new_product_info.append(p)\n",
    "            product_info = new_product_info\n",
    "\n",
    "            print('After:', len(product_info),'\\n')\n",
    "\n",
    "    # split the tuples for threading\n",
    "    split = 4\n",
    "\n",
    "    while len(product_info) // split > 50:\n",
    "        split += 4\n",
    "\n",
    "    print('Split:', split)\n",
    "\n",
    "    list_length = len(product_info) // split\n",
    "    remainder = len(product_info) % split\n",
    "\n",
    "    tuples = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(split):\n",
    "        end = start + list_length\n",
    "        if i >= split - remainder:\n",
    "            end += 1\n",
    "        tuples.append(product_info[start:end])\n",
    "        start = end\n",
    "\n",
    "    # Print the list of tuples line\n",
    "    print(len(tuples[0]))\n",
    "    # print('\\n'.join(f'{i+1}: {t}' for i, t in enumerate(map(str, tuples))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(index_tuple):\n",
    "    worker_id, products = index_tuple\n",
    "    # Create Firefox options\n",
    "    firefox_options = webdriver.FirefoxOptions()\n",
    "    firefox_options.add_argument(\"--private\")  # Open Firefox in private mode\n",
    "    firefox_options.add_argument(\"--lang=zh-TW\")  # Set the language to English (en)\n",
    "    firefox_options.add_argument(\"--window-position=0,0\")  # Set the initial window position\n",
    "\n",
    "    # Create Chrome options\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--incognito\")  # Open Chrome in incognito mode\n",
    "    chrome_options.add_argument(\"--lang=zh-TW\")  # Set the language to Traditional Chinese (zh-TW)\n",
    "    chrome_options.add_argument(\"--window-position=0,0\")  # Set the initial window position\n",
    "\n",
    "    promotion_items = []\n",
    "    index_items = []\n",
    "\n",
    "    for index, row in enumerate(products):\n",
    "        category, product_id, sasa_url = row\n",
    "\n",
    "        # try:\n",
    "        if 'browser' not in locals():\n",
    "            time.sleep(worker_id % 4)\n",
    "            \n",
    "            # Browser open\n",
    "            success = False\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    \n",
    "                    print(f'{worker_id}: Open browser')\n",
    "                    \n",
    "                    # # Create the Firefox browser with the options\n",
    "                    # browser = webdriver.Firefox(options=firefox_options)\n",
    "                    \n",
    "                    # Create the Chrome browser with the options\n",
    "                    browser = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "                    for j in range(3):\n",
    "                        browser.get(sasa_url)\n",
    "                        time.sleep(3)\n",
    "\n",
    "                        print('{}: Open {}: {}'.format(worker_id, category, sasa_url))\n",
    "                    \n",
    "                        if browser.title not in ['', 'None', None]:\n",
    "                            print(\"{}: Page title was '{}'\".format(worker_id, browser.title))\n",
    "                            success = True\n",
    "                            break\n",
    "                        else:\n",
    "                            print('{}: Retry to open {}: {} Attempt {}'.format(worker_id, category, sasa_url, j+1))\n",
    "                        time.sleep(1)\n",
    "\n",
    "                    success = True\n",
    "                    break\n",
    "\n",
    "                except:  # catch all exceptions\n",
    "                    if browser:  # if browser is not None\n",
    "                        browser.quit()  # close the browser\n",
    "                    print('{}: Error A Failed to open {}: {}'.format(worker_id, category, sasa_url))\n",
    "\n",
    "            if not success:\n",
    "                print('{}: Error B Failed to open {}: {}'.format(worker_id, category, sasa_url))\n",
    "                    \n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # add implicit wait\n",
    "            browser.implicitly_wait(3)\n",
    "\n",
    "            # try to locate chat button if exist\n",
    "            # .easychat-chat-dismiss-button-mobile\n",
    "            try:\n",
    "                chat_button = browser.find_element(By.XPATH, '//div[@class=\"easychat-chat-dismiss-button-mobile\"]')\n",
    "                chat_button.click()\n",
    "                # print('chat button closed')\n",
    "            except:\n",
    "                # print('no chat button found')\n",
    "                pass\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                cookie_button = browser.find_element(By.CSS_SELECTOR, 'a.ns-cookie-privacy-agree-btn')\n",
    "                cookie_button.click()\n",
    "                # print('cookie button closed')\n",
    "            except:\n",
    "                # print('no cookie button found')\n",
    "                pass\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        else:  # if browser is already open\n",
    "            success = False\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    # Browser netvigates to the sasa_url\n",
    "                    browser.get(sasa_url)\n",
    "                    time.sleep(1)\n",
    "\n",
    "                    # print('{} Open {}: {}'.format(index, category, sasa_url))\n",
    "                    # print(\"Page title was '{}'\".format(browser.title))\n",
    "\n",
    "                    if browser.title not in ['', 'None', None]:\n",
    "                        success = True\n",
    "                        if i > 0:\n",
    "                            print(\"{}: Page title was '{}'\".format(worker_id, browser.title))\n",
    "                        break\n",
    "                    else:\n",
    "                        print('{}: Retry to open {}: {} Attempt {}'.format(worker_id, category, sasa_url, j+1))\n",
    "                        time.sleep(1)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if not success:\n",
    "                print('{}: Error in browser already open, Failed to open {}: {}'.format(worker_id, category, sasa_url))\n",
    "\n",
    "        #scroll down\n",
    "        new_inner_window_position = browser.execute_script(\"return window.pageYOffset;\")\n",
    "        browser.execute_script('window.scrollBy(0, 1440)') # use seleneium to run JS to scroll down\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # # Promotions\n",
    "        # # Expand the promotions if there are more promotions\n",
    "        # # find salepage-promotion-more\n",
    "\n",
    "        # # Try to find the 'salepage-promotion-more' div\n",
    "        # try:\n",
    "        #     promotion_more = browser.find_element(By.XPATH, '//div[@class=\"salepage-promotion-more\"]')\n",
    "        # except:\n",
    "        #     promotion_more = None\n",
    "\n",
    "        # Initialize a counter\n",
    "        promotion_more_counter = 0\n",
    "\n",
    "        # Try to find the 'salepage-promotion-more' div\n",
    "        while promotion_more_counter < 3:\n",
    "            try:\n",
    "                promotion_more = browser.find_element(By.XPATH, '//div[@class=\"salepage-promotion-more\"]')\n",
    "                if promotion_more and promotion_more.text == '查看更多':\n",
    "                    while promotion_more.text == '查看更多':\n",
    "                        browser.execute_script('window.scrollBy(0,100)')  # Scroll down\n",
    "                        promotion_more.click()  # Click the div\n",
    "                        promotion_more = browser.find_element(By.XPATH, '//div[@class=\"salepage-promotion-more\"]')\n",
    "                        if not promotion_more or promotion_more.text != '查看更多':\n",
    "                            break  # Break the loop\n",
    "                        time.sleep(1)\n",
    "                else:\n",
    "                    promotion_more_counter += 1\n",
    "                    time.sleep(1)\n",
    "            except:\n",
    "                promotion_more_counter += 1\n",
    "                time.sleep(1)\n",
    "\n",
    "        if promotion_more_counter == 3:\n",
    "            print(\"Failed to find 'salepage-promotion-more' div after 3 attempts\")\n",
    "\n",
    "        # # If the div is found and its text is '查看更多', enter a loop\n",
    "        # if promotion_more and promotion_more.text == '查看更多':\n",
    "        #     while promotion_more.text == '查看更多':\n",
    "        #         browser.execute_script('window.scrollBy(0,100)')  # Scroll down\n",
    "        #         try:\n",
    "        #             promotion_more.click()  # Click the div\n",
    "        #             promotion_more = browser.find_element(By.XPATH, '//div[@class=\"salepage-promotion-more\"]')\n",
    "        #         except:\n",
    "        #             promotion_more = None\n",
    "        #         if promotion_more and promotion_more.text != '查看更多':\n",
    "        #             break  # Break the loop\n",
    "        #         time.sleep(1)\n",
    "\n",
    "        # Get the page source and create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        # Find the 'salepage-top-left' div\n",
    "        top_left = soup.find('div', {'class': 'salepage-top-left'})\n",
    "\n",
    "        # # Find the 'salepage-promotion-more' div\n",
    "        # promotion_more = top_left.find('div', {'class': 'salepage-promotion-more'})\n",
    "\n",
    "        # # Click the '查看更多' button until it's no longer available\n",
    "        # while promotion_more and promotion_more.text == '查看更多':\n",
    "        #     # print(promotion_more.text)\n",
    "        #     promotion_more.click()\n",
    "        #     # print('promotion_more clicked')\n",
    "        #     promotion_more = top_left.find('div', {'class': 'salepage-promotion-more'})\n",
    "\n",
    "        # Find all 'salepage-promotion' divs\n",
    "        divs = top_left.find_all('div', {'class': 'salepage-promotion'})\n",
    "\n",
    "        promotion_tags = []\n",
    "        promotion_titles = []\n",
    "\n",
    "        if divs:\n",
    "            for div in divs:\n",
    "                lis = div.find_all('li', {'class': 'salepage-promotion-li'})\n",
    "                if lis:\n",
    "                    for li in lis:\n",
    "                        tag = li.find('div', {'class': 'tag-rectangle'})\n",
    "                        span = li.find('span', {'class': 'salepage-promotion-title'})\n",
    "                        promotion_tags.append(tag.text)\n",
    "                        promotion_titles.append(span.text)\n",
    "\n",
    "        # print('Promotion tags:', promotion_tags)\n",
    "        # print('Promotion titles:', promotion_titles)\n",
    "        # Find the 'salepage-top-right' div\n",
    "        top_right = soup.find('div', {'class': 'salepage-top-right'})\n",
    "\n",
    "        # Find all 'salepage-tag-ul' uls\n",
    "        salepage_tag_uls = []\n",
    "        uls = top_right.find_all('ul', {'class': 'salepage-tag-ul'})\n",
    "        for ul in uls:\n",
    "            lis = ul.find_all('li')\n",
    "            for li in lis:\n",
    "                salepage_tag_uls.append(li.text)\n",
    "\n",
    "        # print('salepage-tag-ul:', salepage_tag_uls, type(salepage_tag_uls))\n",
    "\n",
    "        # Find the 'star-rate' div\n",
    "        star_rate = top_right.find('div', {'class': 'star-rate'})\n",
    "\n",
    "        # Find the star rate and the number of comments\n",
    "    # Find the star rate and the number of comments\n",
    "        if star_rate:\n",
    "            try:\n",
    "                numbers = re.findall(r'\\d+\\.\\d+|\\d+', star_rate.text)\n",
    "                rate, comment = map(float, numbers)\n",
    "                comment = int(comment)\n",
    "                # print('Rate:', rate, type(rate))\n",
    "                # print('Comment:', comment, type(comment))\n",
    "            except:\n",
    "                rate = 'None'\n",
    "                comment = 'None'\n",
    "                # print('no rating found')\n",
    "                # print('Rate:', rate, type(rate))\n",
    "                # print('Comment:', comment, type(comment))\n",
    "        else:  # if star_rate is None\n",
    "            # print('Else:')\n",
    "            rate = 'None'\n",
    "            comment = 'None'\n",
    "            # print('no rating found')\n",
    "            # print('Rate:', rate, type(rate))\n",
    "            # print('Comment:', comment, type(comment))\n",
    "\n",
    "        # Find the 'choose-sku' div\n",
    "        choose_sku = top_right.find('div', {'class': 'choose-sku'})\n",
    "        if choose_sku:\n",
    "            level_sku = len(choose_sku.find_all('li', {'class': 'sku-li'}))\n",
    "            # print('Level of SKU:', level_sku)\n",
    "        else:\n",
    "            # print('no choose-sku found')\n",
    "            sku = None\n",
    "\n",
    "        # Price\n",
    "        price = top_right.find('div', {'class': 'salepage-price'}).text\n",
    "        price = get_currency(price)\n",
    "        # print('Price:', price, type(price))\n",
    "\n",
    "        # Suggest price\n",
    "        try:\n",
    "            original_price = top_right.find('div', {'class': 'salepage-suggestprice'}).text\n",
    "            original_price = get_currency(original_price)\n",
    "            # print('Original Price:', original_price, type(original_price))\n",
    "        except:\n",
    "            original_price = price\n",
    "            # print('No Original Price found')\n",
    "\n",
    "        # Brand\n",
    "        brand_ul = top_right.find('ul', {'class': 'salepage-brand-list'})\n",
    "        brand = brand_ul.text.strip() if brand_ul else None\n",
    "        # print('Brand:', brand, type(brand))\n",
    "\n",
    "        # salepage-feature\n",
    "        salepage_feature_lis = []\n",
    "        features = top_right.find_all('ul', {'class': 'salepage-feature'})\n",
    "        for feature in features:\n",
    "            lis = feature.find_all('li', {'class': 'salepage-feature-li'})\n",
    "            # print('lis:', lis, type(lis))\n",
    "            for li in lis:\n",
    "                for div in li.find_all('div'):\n",
    "                    # Strip leading/trailing whitespace from the text and add it to the list\n",
    "                    salepage_feature_lis.append(div.text.strip())\n",
    "\n",
    "        # salepage_feature_lis to a single string\n",
    "        features = '<br>'.join(salepage_feature_lis)\n",
    "        # print('Features:', features, type(features))\n",
    "\n",
    "        promotion_items.extend([(product_id, tag, title) for tag, title in zip(promotion_tags, promotion_titles)])\n",
    "\n",
    "        index_items.extend([(product_id, rate, comment, price, original_price, brand, features)])\n",
    "\n",
    "    browser.quit()\n",
    "    print('{}: Close browser'.format(worker_id))\n",
    "\n",
    "    # print('Promotion items:', promotion_items)\n",
    "    # print('Index items:', index_items)\n",
    "\n",
    "    # open csv\n",
    "    with open(promo_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerows(promotion_items)\n",
    "\n",
    "    with open(index_filename, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerows(index_items)\n",
    "\n",
    "    print('{}: Done'.format(worker_id))\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(promo_filename)\n",
    "print(index_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_start_time = time.time()\n",
    "\n",
    "# Process each tuple\n",
    "results = get_product_info(product_info)\n",
    "\n",
    "# Concatenate the first dataframes into a master dataframe\n",
    "master_df1 = pd.concat([result[0] for result in results], ignore_index=True)\n",
    "\n",
    "# Concatenate the second dataframes into another master dataframe\n",
    "master_df2 = pd.concat([result[1] for result in results], ignore_index=True)\n",
    "\n",
    "master_end_time = time.time()\n",
    "print(f\"Elapsed time: {(master_end_time - master_start_time) / 60:,.0f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sasa/sasa_promotion_{}.csv'.format(datetime.now().strftime('%Y%m%d'))\n",
    "if filename.split('/')[1] in os.listdir('sasa'):\n",
    "    os.remove(filename)\n",
    "    print('Old file removed:', filename)\n",
    "master_df1.to_csv(filename, index=False)\n",
    "\n",
    "print('Promotion Dataframe saved to:', filename.split('/')[1])\n",
    "\n",
    "display(master_df1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
